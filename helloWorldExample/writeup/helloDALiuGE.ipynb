{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello DALiuGE: Unnecessarily Complicated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "### Nicholas Pritchard "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook introduces the essential components of the [DALiuGE](https://github.com/ICRAR/daliuge) framework, presents several trivial example workflows with the ultimate goal of demonstrating what reproducible data processing practically involves.\n",
    "\n",
    "1. We outline some basics about [DALiuGE](https://github.com/ICRAR/daliuge) and DROP-based execution.\n",
    "2. Several trivial 'Hello World' example workflows are illustrated using raw DROPS\n",
    "3. These are converted to launchable Logical Graph Templates \n",
    "4. We introduce and illustrate several methodologies to reproduce various workflow behaviours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DALiuGE and DROPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Data Activate Liu (Flow) Graph Engine is a workflow graph based execution framework in development for eventual deployment with the Science Data Processor (SDP) for the Square Kilometre Array (SKA).\n",
    "\n",
    "A DROP is the abstraction for workflow component which encoumpasses both data and computing elements. \n",
    "\n",
    "DROPs can:\n",
    "- Produce input for another DROP\n",
    "- Consume the output of another DROP\n",
    "\n",
    "Once deployed by DALiuGE a DROP fires events describing its runtime state. Producers signal to their consumers when their data is ready. Once all of a DROP's producers have finished it begins execution; this is the main mechanism driving workflow execution. \n",
    "\n",
    "The goal is to rigorously design and test DROPs for re-use by Astronomers. The detail of how an entire workflow graph (Logical Graph Template) is instantiated is beyond the scope of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our DROPs\n",
    "\n",
    "We draw your attention to four types of DROPs used in this notebook\n",
    "- File\n",
    "  - Represents a literal file in a directory.\n",
    "  - A file DROP acting as a producer is analogous to reading\n",
    "  - A file DROP acting as a consumer is analogous to writing\n",
    "- InMemory\n",
    "  - Represents a datastore in memory.\n",
    "  - Functions similar to a file but only exists during runtime\n",
    "- BashShell\n",
    "  - Executes a 'command' argument in a bash-shell\n",
    "  - Can consume or produce 'streaming' input or output which is processed line by line \n",
    "- PythonScript\n",
    "  - Executes a simple Python function similar to a bash script.\n",
    "  \n",
    "Eventually, we will see how to specify a new DROP type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello World - Everyone's First Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 'hello world' program is the canonical first example used to demonstrate a new programming language or execution environment.\n",
    "\n",
    "The goal is to of course output 'Hello World' in some form. We extend this to a 'Hello [S]' example where [S] is an arbitrary string of characters.\n",
    "\n",
    "Instead of outputting to a screen, we output data to a File DROP.\n",
    "\n",
    "We now proceed with several ways to achieve this trivial task using DROPs.\n",
    "\n",
    "First, we setup pre-amble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from dlg.apps.bash_shell_app import StreamingInputBashApp, StreamingOutputBashApp\n",
    "from dlg.apps.pyfunc import PyFuncApp\n",
    "from dlg.ddap_protocol import DROPStates\n",
    "from dlg.drop import FileDROP, InMemoryDROP, BarrierAppDROP\n",
    "from dlg.droputils import allDropContents\n",
    "from six import BytesIO\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hello World\n",
    "This example writes 'Hello World' to a file directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_fname = os.getcwd() + '/result.out'\n",
    "\n",
    "# Initialize our Drops\n",
    "a = FileDROP('a', 'a', filepath=output_fname)\n",
    "\n",
    "# Link Drops together\n",
    "\n",
    "# Execute and wait \n",
    "a.write(b\"Hello world\")\n",
    "a.setCompleted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FileDROP oid=a, uid=a>\n",
      "2\n",
      "True\n",
      "b'Hello world'\n"
     ]
    }
   ],
   "source": [
    "# Inspect Results\n",
    "print(a)\n",
    "print(a.status)\n",
    "print(a.status == DROPStates.COMPLETED)\n",
    "\n",
    "# Check the file was written correctly\n",
    "print(allDropContents(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hello World Bash\n",
    "A slightly more convoluted setup where a bash script echoes 'Hello World'. DALiuGE then writes this output to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_fname = os.getcwd() + '/result.out'\n",
    "\n",
    "# Initialize our Drops\n",
    "a = StreamingOutputBashApp('a', 'a', command=r\"echo -en 'Hello world'\")\n",
    "b = InMemoryDROP('b', 'b')\n",
    "c = StreamingInputBashApp('c', 'c', command=\"cat > %o0\")\n",
    "d = FileDROP('d', 'd', filepath=output_fname)\n",
    "\n",
    "# Link Drops together\n",
    "a.addOutput(b)\n",
    "c.addStreamingInput(b)\n",
    "c.addOutput(d)\n",
    "\n",
    "# Execute and wait \n",
    "a.async_execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<StreamingOutputBashApp oid=a, uid=a>\n",
      "2\n",
      "True\n",
      "<InMemoryDROP oid=b, uid=b>\n",
      "2\n",
      "True\n",
      "<StreamingInputBashApp oid=c, uid=c>\n",
      "2\n",
      "True\n",
      "<FileDROP oid=d, uid=d>\n",
      "2\n",
      "True\n",
      "b'Hello world'\n"
     ]
    }
   ],
   "source": [
    "# Inspect Results\n",
    "for drop in (a, b, c, d):\n",
    "    print(drop)\n",
    "    print(drop.status)\n",
    "    print(drop.status == DROPStates.COMPLETED)\n",
    "\n",
    "# Check the file was written correctly\n",
    "print(allDropContents(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hello World Python\n",
    "This example achieves identical functionality to the previous example but using a python function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_fname = os.getcwd() + '/result6.out'\n",
    "\n",
    "\n",
    "def hello_world():\n",
    "    return \"Hello World\"\n",
    "\n",
    "fname = '__main__.hello_world'\n",
    "\n",
    "# Initialize our Drops\n",
    "a = PyFuncApp('a', 'a', func_name=fname)\n",
    "b = FileDROP('b', 'b', filepath=output_fname)\n",
    "\n",
    "# Link Drops together\n",
    "a.addOutput(b)\n",
    "\n",
    "# Execute and wait \n",
    "a.async_execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PyFuncApp oid=a, uid=a>\n",
      "2\n",
      "True\n",
      "<FileDROP oid=b, uid=b>\n",
      "2\n",
      "True\n",
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "# Inspect Results\n",
    "for drop in (a, b):\n",
    "    print(drop)\n",
    "    print(drop.status)\n",
    "    print(drop.status == DROPStates.COMPLETED)\n",
    "\n",
    "# Check the file was written correctly\n",
    "print(pickle.loads(allDropContents(b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hello S Bash\n",
    "The first 'dynamic' example where a bash script echoes a string as streaming output, a second script captures this output as a streaming input, prepends each line with 'Hello' and echoes this new text. DALiuGE finally writes this result to file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_fname = os.getcwd() + '/result3.out'\n",
    "\n",
    "# Initialize our drops\n",
    "a = StreamingOutputBashApp('a', 'a', command=r\"echo -en 'world'\")\n",
    "b = InMemoryDROP('b', 'b')\n",
    "c = StreamingInputBashApp('c', 'c', command=\"echo Hello $(cat) > %o0\")\n",
    "d = FileDROP('d', 'd', filepath=output_fname)\n",
    "\n",
    "# Link Drops together\n",
    "a.addOutput(b)\n",
    "c.addStreamingInput(b)\n",
    "c.addOutput(d)\n",
    "\n",
    "# Execute and wait\n",
    "a.async_execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<StreamingOutputBashApp oid=a, uid=a>\n",
      "2\n",
      "True\n",
      "<InMemoryDROP oid=b, uid=b>\n",
      "2\n",
      "True\n",
      "<StreamingInputBashApp oid=c, uid=c>\n",
      "2\n",
      "True\n",
      "<FileDROP oid=d, uid=d>\n",
      "2\n",
      "True\n",
      "b'Hello world\\n'\n"
     ]
    }
   ],
   "source": [
    "# Inspect Results\n",
    "for drop in (a, b, c, d):\n",
    "    print(drop)\n",
    "    print(drop.status)\n",
    "    print(drop.status == DROPStates.COMPLETED)\n",
    "\n",
    "# Check the file was written correctly\n",
    "print(allDropContents(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hello S Python\n",
    "This example achieves identical functionality to the previous example but uses a python function. Notice that we write data using the pickle submodule. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_fname = os.getcwd() + '/result.out'\n",
    "\n",
    "def hello_world(s='Everybody'):\n",
    "    return \"Hello \" + s\n",
    "\n",
    "fname = '__main__.hello_world'\n",
    "\n",
    "# Initialize our Drops\n",
    "a = InMemoryDROP('a', 'a')\n",
    "b = PyFuncApp('b', 'b', func_name=fname)\n",
    "c = FileDROP('c', 'c', filepath=output_fname)\n",
    "\n",
    "# Link Drops together\n",
    "b.addInput(a)\n",
    "b.addOutput(c)\n",
    "\n",
    "# Execute and wait (HACK)\n",
    "a.write(pickle.dumps(\"World\"))\n",
    "a.setCompleted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<InMemoryDROP oid=a, uid=a>\n",
      "2\n",
      "True\n",
      "<PyFuncApp oid=b, uid=b>\n",
      "2\n",
      "True\n",
      "<FileDROP oid=c, uid=c>\n",
      "2\n",
      "True\n",
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "# Inspect Results\n",
    "for drop in (a, b, c):\n",
    "    print(drop)\n",
    "    print(drop.status)\n",
    "    print(drop.status == DROPStates.COMPLETED)\n",
    "\n",
    "# Check the file was written correctly\n",
    "print(pickle.loads(allDropContents(c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hello S Drop\n",
    "We now see how a simple DROP can be defined.\n",
    "\n",
    "This example features a new `PrependResult` DROP which extends a `BarrierApp` DROP. All drops need to implement a data URL method, initialisation method (allowing you to add new arguments, in our case, the 'prefix' argument) and a run method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrependResult(BarrierAppDROP):\n",
    "    def dataURL(self):\n",
    "        pass\n",
    "\n",
    "    def initialize(self, **kwargs):\n",
    "        super(PrependResult, self).initialize(**kwargs)\n",
    "        self.prefix = bytes(kwargs['prefix'], 'utf-8')\n",
    "\n",
    "    def run(self):\n",
    "        curr_drop = self.inputs[0]\n",
    "        output = self.outputs[0]\n",
    "        all_lines = BytesIO(allDropContents(curr_drop)).readlines()\n",
    "        for line in all_lines:\n",
    "            output.write(self.prefix + line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_fname = os.getcwd() + '/result.out'\n",
    "# Initialize our drops\n",
    "a = InMemoryDROP('a', 'a')\n",
    "b = PrependResult('b', 'b', prefix='Hello ')\n",
    "c = FileDROP('c', 'c', filepath=output_fname)\n",
    "\n",
    "# Link Drops together\n",
    "a.addConsumer(b)\n",
    "b.addOutput(c)\n",
    "\n",
    "# Execute and wait (HACK)\n",
    "a.write(b\"world\")\n",
    "a.setCompleted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<InMemoryDROP oid=a, uid=a>\n",
      "2\n",
      "True\n",
      "<PrependResult oid=b, uid=b>\n",
      "2\n",
      "True\n",
      "<FileDROP oid=c, uid=c>\n",
      "2\n",
      "True\n",
      "b'Hello world'\n"
     ]
    }
   ],
   "source": [
    "# Inspect Results\n",
    "for drop in (a, b, c):\n",
    "    print(drop)\n",
    "    print(drop.status)\n",
    "    print(drop.status == DROPStates.COMPLETED)\n",
    "\n",
    "# Check the file was written correctly\n",
    "print(allDropContents(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far all these examples execute DROPs natively and locally.\n",
    "\n",
    "To leverage remote and likely expansive compute resources DALiuGE is designed to accept workflow specifications at various stages of specificity in the following methodology:\n",
    "1. Astronomers design a Logical Graph Template (LGT) specifying a workflow at the highest abstraction level.\n",
    "  - Comprised of DROPs and Control Components describing how parallelism is to be exploited (GROUP BY, SCATTER/GATHER etc.)\n",
    "  - Should be the only major astronomer intervention before runtime\n",
    "  - Each subsequent step occurs within the DALiuGE install. \n",
    "2. `Fill`\n",
    "  - Input: A Logical Graph Template (LGT) file\n",
    "  - Output: A Logical Graph (LG)\n",
    "  - Parameterises a graph template with specific design details such as SCATTER axes or other run-specific details. Indended to facilitate LGT reuse with multiple telescope surveys\n",
    "  - Occurs months before execution\n",
    "3. `Unroll`\n",
    "  - Input: A Logical Graph\n",
    "  - Output: A Physical Graph Template (PGT)\n",
    "  - Converts a logical graph to a fully atomic PGT comprised of all DROPs and all relationships.\n",
    "  - Group controls such as loops are 'unrolled' into a fully verbose DAG workflow.\n",
    "  - Occurs weeks before execution\n",
    "4. `Partition`\n",
    "  - Input: A Physical Graph Template (PGT), Machine specification, Algorithm Choice\n",
    "  - Output: A Physical Graph Template (PGT)\n",
    "  - DROPs are grouped by resource requirements. This is where parallelism is introduced into the execution. Partitions can be launched on separate machines simultaneously.\n",
    "  - The resulting partitioned PGT can vary greatly depending on the algorithm used and target machine. We expect a given PGT will undergo several different partitioning rounds to establish one that is most suitable\n",
    "  - Occurs weeks before execution.\n",
    "  \n",
    "5. `Map`\n",
    "  - Input: A Partitioned Physical Graph Template (PGT), Machine specification\n",
    "  - Output: A Physical Graph (PG)\n",
    "  - Provides exact IP addresses and machine information for all DROPS. The resulting Physical Graph specifies a computation exactly.\n",
    "  - Occurs minutes before execution\n",
    "6. `Submit`\n",
    "  - Input: A Physical Graph (PG)\n",
    "  - Output: Data artefacts and/or Reproducibility File \n",
    "  - DALiuGE instantiates the drops specified in the PG and orchestrates the successive firing of DROPs until exeuction completes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launchable Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducible Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helloworld",
   "language": "python",
   "name": "helloworld"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
